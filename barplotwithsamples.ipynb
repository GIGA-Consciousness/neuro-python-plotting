{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar plot with confidence interval and samples\n",
    "This notebook plots a bar graph from per-subject values extracted from REX (or another software) and plots the 90% confidence interval and all per-subject values as scatterplots.\n",
    "\n",
    "If in addition you supply the ROIs nifti images (one per ROI), you will in addition get a nice glass brain image with all ROIs, and the bar plot will also include additional infos (ROI center coordinates + atlas regions names covered by ROI + same color of text as the glass brain).\n",
    "\n",
    "Version 1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# BEWARE: autoreload works on functions and on general code, but NOT on new class methods:\n",
    "# if you add or change the name of a method, you have to reload the kernel!\n",
    "# also it will fail if you use super() calls in the classes you change\n",
    "# ALSO AUTORELOAD SHOULD BE THE FIRST LINE EVER EXECUTED IN YOUR IPYTHON NOTEBOOK!!!\n",
    "\n",
    "# Profilers:\n",
    "# http://pynash.org/2013/03/06/timing-and-profiling/\n",
    "# http://mortada.net/easily-profile-python-code-in-jupyter.html\n",
    "# use %lprun -m module func(*args, **kwargs)\n",
    "try:\n",
    "    %load_ext line_profiler\n",
    "    %load_ext memory_profiler\n",
    "except ImportError as exc:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate figure inside IPython Notebook (must be called before any import of matplotlib, direct or indirect!)\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltcol\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "try:\n",
    "    from adjustText import adjust_text  # you will need this lib if you want to plot subjects ids without overlap: pip install adjustText\n",
    "except ImportError as exc:  # else we will just plot the subjects labels without any adjustment (so the position can overlap with the points and with each others)\n",
    "    adjust_text = None\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PARAMETERS - EDIT ME\n",
    "groups = [9, 9]  # set the number of items/values for each group\n",
    "groups_labels = ['S2', 'W1']  # set names for each group\n",
    "groups_order = range(len(groups))  # in which order we plot each bar. Leave as is to plot bars in the original order, or provide list of group nb to shuffle as you want (this is only a display parameter, it does not change the results)\n",
    "#subjects_labels = range(1, sum(groups)+1)  # set ID for each subject (can be any string, all that matters is that it is the same order as the input values: first value here is the first value in imported rex data file, etc)\n",
    "#subjects_labels = range(1, groups[0]+1)*len(groups)  # use this for within-subject analyses, where you want the labels to be the same range in both bars\n",
    "show_subjects_labels = True  # show label for each subject's point?\n",
    "show_subjects_paired = True  # paired/longitudinal analysis, both groups contain in fact the same subjects but in different conditions, enable this option to restart counting subjects ids to 1 for each condition\n",
    "rex_data_filepath = ['testconjunc.cluster00%i.rex.data.txt' % i for i in xrange(1,6)]\n",
    "rex_maps_filepath = ['testconjunc.cluster00%i.rex.roi.img' % i for i in xrange(1,6)]  # specify here the filenames, in the same order as the input text files, to plot the ROIs on a brain using nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_maps(list_imgs, voxel_threshold=None):\n",
    "    if voxel_threshold is None:\n",
    "        voxel_threshold = 0.0001 # minimum threshold to consider as a voxel and not just background noise (because background voxels can be 0.000001 for example), can be float or str ('1%' to give a percentage). TODO: autodetect minimum value (can be -4, 0.02, etc) as the background and use it as the threshold value.\n",
    "    # Load masks and resample to first\n",
    "    imgs = []\n",
    "    for img in list_imgs:\n",
    "        im = image.load_img(img)\n",
    "        if imgs:\n",
    "            if im.shape != imgs[0].shape:\n",
    "                im = image.resample_to_img(im, imgs[0])\n",
    "        im = image.threshold_img(im, voxel_threshold)\n",
    "        imgs.append(im)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SANITY CHECKS\n",
    "#if show_subjects_labels:\n",
    "    #if len(subjects_labels) != sum(groups):\n",
    "        #raise(ValueError('subjects_labels does not contain the same number of subjects as groups!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading data from Rex csv\n",
    "dfraw = []\n",
    "nb_rois = len(rex_data_filepath)\n",
    "for fpath in rex_data_filepath:\n",
    "    dfraw.append(pd.read_csv(fpath, index_col=False, header=None, squeeze=True))\n",
    "    if len(dfraw[-1]) != sum(groups):\n",
    "        raise(ValueError('the number of values in the provided txt file is not the same as the supplied groups count (ie, you did not specify the correct number of subjects!), please check your parameters!'))\n",
    "    print(dfraw[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the values for each group in a separate dataframe\n",
    "df_g = []\n",
    "for i in xrange(nb_rois):\n",
    "    start = 0\n",
    "    for g in groups:\n",
    "        df_g.append(dfraw[i][start:start+g])\n",
    "        start = g\n",
    "        if show_subjects_paired:\n",
    "            # Reset indices to restart at 0 the subjects counting because it's the same subjects (longitudinal analysis)\n",
    "            df_g[-1].index = list(range(0,len(df_g[-1])))\n",
    "        #else:\n",
    "            # Continue the numbering (different groups of subjects)\n",
    "\n",
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "def comp_ci(a):\n",
    "    '''Calculates the 90% confidence interval from a vector.\n",
    "    From the excellent SO answer by Ulrich Stern: https://stackoverflow.com/a/34474255/1121352'''\n",
    "    return scipy.stats.t.interval(0.90, len(a)-1, loc=np.mean(a), scale=scipy.stats.sem(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cluster_center(im, mricron=False):\n",
    "    from nilearn.image.resampling import reorder_img, coord_transform\n",
    "    # Project coordinates to reduced space\n",
    "    if mricron:\n",
    "        im2 = reorder_img(im, resample='continuous')  # DO NOT USE: this will convert to MRIcron coordinates space (ie, [0, 100]) but it will mess things up for nilearn!\n",
    "        # Get indices of nonzero values\n",
    "        matches = im2.get_data().nonzero()\n",
    "    else:\n",
    "        # Get indices of nonzero values\n",
    "        matches = im.get_data().nonzero()\n",
    "    # Compute the euclidian middle of the cluster, from the nonzero values indices (= coordinates)\n",
    "    center = np.mean(matches, axis=1)\n",
    "    # Project center coordinates to brain space (ie, instead of [0, 100] range, it will be [-50, 50] -- I picked these numbers randomly, you see the idea)\n",
    "    if not mricron:\n",
    "        center = coord_transform(center[0], center[1], center[2], im.affine)  # disable this to get MRIcron space\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot ROIs on glass brain images!\n",
    "if rex_maps_filepath:\n",
    "    imgs = load_maps(rex_maps_filepath)\n",
    "\n",
    "    #plotting.plot_prob_atlas(imgs, view_type=\"filled_contours\",\n",
    "    #                    title=\"lala\", colorbar=True, cut_coords=(0,0,0), draw_cross=True, cmap=pltcol.ListedColormap(['b', 'g', 'r', 'c', 'm'], name='from_list', N=None))\n",
    "    #plotting.plot_roi(imgs[0])\n",
    "\n",
    "    centers = []\n",
    "    fig = plotting.plot_glass_brain(None, title='ROIs', cmap=plt.cm.prism, alpha=0.5)  # initialize the glass brain images\n",
    "    for c, im in enumerate(imgs):\n",
    "        # For each ROI\n",
    "        # Get the center (to plot the marker)\n",
    "        center = find_cluster_center(im)\n",
    "        centers.append(center)\n",
    "        print('Center found at: ' + str(center))\n",
    "        # Assign a unique value to this cluster's voxels (to get a different color)\n",
    "        imdata = im.get_data()  # Convert to numpy structure\n",
    "        imdata[imdata != 0] = c+1  # Assign unique value\n",
    "        im2 = nib.Nifti1Image(imdata, affine=im.affine)  # convert back to a nifti file in-memory to supply to nilearn\n",
    "        # Show colorbar?\n",
    "        cbar = False\n",
    "        if c == (nb_rois-1):\n",
    "            # Can only plot the colorbar at the last iteration, else nilearn will spit an error (cannot use multiple colorbars)\n",
    "            cbar = True\n",
    "        # Plot the clusters\n",
    "        fig.add_overlay(im2, vmin=1, vmax=nb_rois, cmap=plt.cm.prism, colorbar=cbar)\n",
    "        # Plot the markers (clusters' centers)\n",
    "        fig.add_markers([center], marker_color=['k'], marker_size=20)\n",
    "\n",
    "# Save figure\n",
    "fig.savefig('rois_glass_brain.png', bbox_inches='tight')\n",
    "print('Image saved in rois_glass_brain.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nilearn import plotting, datasets\n",
    "\n",
    "def get_atlas_label(atlas, region_idx):\n",
    "    \"\"\"\n",
    "    Get atlas label for one specific region index\n",
    "    \"\"\"\n",
    "    return atlas['labels'][atlas['indices'].index(str(region_idx))]\n",
    "\n",
    "def get_atlas_labels(imgs, atlas_choice='aal2', verbose=False):\n",
    "    \"\"\"\n",
    "    Get the list of atlas regions covered by clusters, from a list of nifti maps loaded in-memory via nibabel\n",
    "    atlas_choice is optional, can be 'aal2' or 'SPM12'\n",
    "    \"\"\"\n",
    "    voxel_threshold = 0.0001 # minimum threshold to consider as a voxel and not just background noise (because background voxels can be 0.000001 for example), can be float or str ('1%' to give a percentage). TODO: autodetect minimum value (can be -4, 0.02, etc) as the background and use it as the threshold value.\n",
    "    # Atlas\n",
    "    atlas_choice = 'aal2' # anatomytoolbox or aal2\n",
    "    if atlas_choice == 'anatomytoolbox':\n",
    "        atlas_path = 'masks\\AnatomyToolbox_Atlas_Map.nii'  # TODO: build atlas variable with all infos and data (labels, indices, nib niftiimage with affine etc)\n",
    "    else:\n",
    "        atlas = datasets.fetch_atlas_aal(version='SPM12', data_dir='atlas')\n",
    "\n",
    "    # Show some infos about atlas\n",
    "    atlas_im = image.load_img(atlas.maps)\n",
    "    if verbose:\n",
    "        print('Atlas shape: %s' % str(atlas_im.shape))\n",
    "    nb_regions = len(np.unique(atlas_im.get_data()))- 1\n",
    "    if verbose:\n",
    "        print('%i regions in this atlas: %s' % (nb_regions, str(np.unique(atlas_im.get_data())))) # 48 regions because 0 is background\n",
    "        print('%i labels' % len(atlas['labels']))\n",
    "        print('%i indices: %s' % (len(atlas['indices']), atlas['indices']))\n",
    "        print(atlas.keys())\n",
    "\n",
    "    # Resample masks to atlas size\n",
    "    imgs2 = []\n",
    "    for img in imgs:\n",
    "        if img.shape != atlas_im.shape:\n",
    "            img = image.resample_to_img(img, atlas_im)\n",
    "        img = image.threshold_img(img, voxel_threshold)\n",
    "        imgs2.append(img)\n",
    "    imgs = imgs2\n",
    "    del imgs2\n",
    "    imgs[0].shape\n",
    "\n",
    "    # Extract activated atlas brain regions for each mask\n",
    "    maps_regions = []\n",
    "    maps_regions_idxs = []\n",
    "    maps_regions_count = []\n",
    "    for img in imgs:\n",
    "        # Extract only non zeros voxels indices from mask\n",
    "        im_data = img.get_data()\n",
    "        #np.extract(im_data>0, im_data)\n",
    "        vox_thres = np.nonzero(im_data)\n",
    "        # Compare with atlas regions to extract region indices\n",
    "        atlas_data = atlas_im.get_data()\n",
    "        region_indices = set()\n",
    "        region_count = {}\n",
    "        for x in zip(*vox_thres): # walk through all non zero voxels of mask\n",
    "            region_idx = atlas_data[x] # get equivalent voxel from atlas\n",
    "            if region_idx != 0: # if not background\n",
    "                # Append region index into the set (so that they are unique)\n",
    "                region_indices.add(region_idx)\n",
    "                # Increase the count of voxels activated in this region\n",
    "                region_label = get_atlas_label(atlas, region_idx)\n",
    "                if region_label not in region_count:\n",
    "                    region_count[region_label] = 0\n",
    "                region_count[region_label] += 1\n",
    "        if 0 in region_indices:\n",
    "            region_indices.remove(0) # remove background, not part of the atlas labels\n",
    "        if verbose:\n",
    "            print('Atlas indices of brain regions activated in current mask: %s' % str(sorted(region_indices)))\n",
    "        # Extract brain region names from atlas that are present in this mask\n",
    "        matching_idxs = [int(idx) in region_indices for idx in atlas['indices']]\n",
    "        map_brain_regions = filter(None, [label if match else None for label, match in zip(atlas['labels'], matching_idxs)])\n",
    "        maps_regions.append(map_brain_regions)\n",
    "        maps_regions_idxs.append(region_indices)\n",
    "        maps_regions_count.append(region_count)\n",
    "\n",
    "    return maps_regions, maps_regions_idxs, maps_regions_count\n",
    "\n",
    "if rex_maps_filepath:\n",
    "    maps_regions, _, _ = get_atlas_labels(imgs)\n",
    "    print('Found the following regions covered by the ROIs clusters:')\n",
    "    for i in xrange(nb_rois):\n",
    "        print('ROI %i: %s' % (i, ', '.join(maps_regions[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot!\n",
    "\n",
    "# Plotting parameters\n",
    "ylim = None  # limit y axis to these values. Set to None to use default limits automatically detected by matplotlib.\n",
    "figsize = [2*nb_rois, 5]  # figure size, in inches, set to None to use default\n",
    "colors = ['b', 'g', 'r', 'y', 'c', 'b']\n",
    "ylabel = 'Effect sizes'\n",
    "width = 1  # width of the bars - do not change, it is an internal parameter and does not impact the visualization\n",
    "ticks = np.arange(1, 1+(width*len(groups)*nb_rois), width)  # do not modify this\n",
    "\n",
    "# Plotting each bar\n",
    "fig, ax = plt.subplots()\n",
    "if figsize:\n",
    "    fig.set_size_inches(figsize[0], figsize[1], forward=True)\n",
    "for roi_id in xrange(nb_rois):\n",
    "    last_j = 0\n",
    "    texts = []\n",
    "    for i, gi in enumerate(groups_order):\n",
    "        # Get the data for the selected group\n",
    "        dg = df_g[len(groups)*roi_id + gi]\n",
    "        # Draw bars with error bar\n",
    "        bar = ax.bar(ticks[len(groups)*roi_id+i], dg.mean(), width=width, yerr=(dg.mean() - comp_ci(dg)[1]), alpha=0.5, color=colors[i], error_kw={'ecolor': 'k', 'elinewidth': 1, 'capsize': 15, 'capthick': 1, 'barsabove': False})\n",
    "        # Add scatter points for each subject\n",
    "        scatter_x = ticks[len(groups)*roi_id+i]+(float(width)/2)\n",
    "        ax.scatter([scatter_x] * len(dg), dg, color=colors[i], marker='x', s=30)\n",
    "        # Add label for each subject scatter point\n",
    "        if show_subjects_labels:\n",
    "            for j, y in enumerate(dg):\n",
    "                text = dg.index.values[j] + 1\n",
    "                t = ax.text(scatter_x, y, text, alpha=0.5)\n",
    "                texts.append(t)\n",
    "            last_j += j+1\n",
    "    # Adjust label for each subject text placement to avoid overlapping\n",
    "    if show_subjects_labels and adjust_text is not None:\n",
    "        #texts = subjects_labels[last_j:end]\n",
    "        adjust_text(texts,\n",
    "                    text_from_points=True,\n",
    "            only_move={'text':'xy', 'objects':'x'}, force_text=0.01, force_objects=1.0) #, arrowprops=dict(arrowstyle=\"->\", color='r', lw=0.5))\n",
    "\n",
    "# Change the ticks to set the groups names (and place the labels nicely)\n",
    "ax.set_xticks([t + float(width)/2 for t in ticks])  # place in the middle of each bar (position tick t + half of bar width)\n",
    "ax.set_xticklabels(groups_labels * nb_rois)\n",
    "# Add ROIs centers, colors and names if available (ie, if maps are provided)\n",
    "norm = pltcol.Normalize(vmin=1,vmax=nb_rois)  # need to normalize the values we will input to the colormap to be onpoint with nilearn\n",
    "for ri in xrange(nb_rois):\n",
    "    ax.text((ri+1)*2, -0.45, '%.0f,%.0f,%.0f\\n%s' % (centers[ri][0], centers[ri][1], centers[ri][2], '\\n'.join(textwrap.wrap(', '.join(maps_regions[ri]), width=30))),\n",
    "            rotation=0, verticalalignment='top', horizontalalignment='center',\n",
    "            #transform=ax.transAxes,\n",
    "            color=plt.cm.prism(norm(ri+1)), fontsize=10)\n",
    "    # pltcol.rgb2hex(plt.cm.prism(norm(ri+1)))  # to get the hex value of the color\n",
    "# Force draw the plot (with tight layout)\n",
    "plt.tight_layout()\n",
    "if ylim:\n",
    "    ax.set_ylim(ylim)\n",
    "ax.set_xlim([ticks[0], ticks[-1]+width])\n",
    "plt.ylabel(ylabel)\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig('rois_bars.png', bbox_inches='tight')\n",
    "print('Image saved in rois_bars.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
